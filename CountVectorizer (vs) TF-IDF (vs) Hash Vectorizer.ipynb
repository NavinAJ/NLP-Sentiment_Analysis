{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>CountVectorizer (vs) TF-IDF (vs) Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = ['Running the example first prints the vocabulary, then the shape of the first encoded document.']\n",
    "Test = ['We can then see that the encoded vector is a sparse matrix of encoded.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=50, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(max_features=50,ngram_range=(1,3))\n",
    "count_vec.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_output = count_vec.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'running': 17, 'the': 23, 'example': 3, 'first': 6, 'prints': 14, 'vocabulary': 35, 'then': 32, 'shape': 20, 'of': 11, 'encoded': 1, 'document': 0, 'running the': 18, 'the example': 24, 'example first': 4, 'first prints': 9, 'prints the': 15, 'the vocabulary': 30, 'vocabulary then': 36, 'then the': 33, 'the shape': 28, 'shape of': 21, 'of the': 12, 'the first': 26, 'first encoded': 7, 'encoded document': 2, 'running the example': 19, 'the example first': 25, 'example first prints': 5, 'first prints the': 10, 'prints the vocabulary': 16, 'the vocabulary then': 31, 'vocabulary then the': 37, 'then the shape': 34, 'the shape of': 29, 'shape of the': 22, 'of the first': 13, 'the first encoded': 27, 'first encoded document': 8}\n",
      "(1, 38)\n",
      "[[0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(count_vec.vocabulary_)\n",
    "print(count_vec_output.shape)\n",
    "print(count_vec_output.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=50,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(max_features=50,ngram_range=(1,3))\n",
    "tfidf_vec.fit(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_output = tfidf_vec.transform(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'running': 17, 'the': 23, 'example': 3, 'first': 6, 'prints': 14, 'vocabulary': 35, 'then': 32, 'shape': 20, 'of': 11, 'encoded': 1, 'document': 0, 'running the': 18, 'the example': 24, 'example first': 4, 'first prints': 9, 'prints the': 15, 'the vocabulary': 30, 'vocabulary then': 36, 'then the': 33, 'the shape': 28, 'shape of': 21, 'of the': 12, 'the first': 26, 'first encoded': 7, 'encoded document': 2, 'running the example': 19, 'the example first': 25, 'example first prints': 5, 'first prints the': 10, 'prints the vocabulary': 16, 'the vocabulary then': 31, 'vocabulary then the': 37, 'then the shape': 34, 'the shape of': 29, 'shape of the': 22, 'of the first': 13, 'the first encoded': 27, 'first encoded document': 8}\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vec.vocabulary_)\n",
    "print(tfidf_vec.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38)\n",
      "[[0.         0.75592895 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.37796447 0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_output.shape)\n",
    "print(tfidf_output.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_vec = HashingVectorizer(n_features=20,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_output = hash_vec.transform(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "[[-0.13867505 -0.13867505  0.          0.          0.          0.\n",
      "   0.         -0.13867505  0.13867505 -0.13867505 -0.2773501   0.41602515\n",
      "   0.13867505  0.          0.5547002   0.          0.          0.13867505\n",
      "  -0.5547002   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(hash_output.shape)\n",
    "print(hash_output.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
